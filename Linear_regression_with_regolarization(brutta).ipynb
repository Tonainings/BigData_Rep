{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PierDiella/BigData_Rep/blob/main/Linear_regression_with_regolarization(brutta).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9EaizqH6QBg"
      },
      "outputs": [],
      "source": [
        "def compute_cost_linear_reg(x, y, w, b, lamda_ = 1): # creazione di una funzione \"compute cost\"\n",
        "\n",
        " m = x.shape[0] # dichiaro che la variabile m è uguale alla dimensione degli elementi di x\n",
        " n = len(w)\n",
        " cost = 0 # dichiaro che la variabile cost (la sola sommatoria della cost_function) sia uguale a 0\n",
        " for i in range(m):\n",
        " #X_i = X[i,:]\n",
        " f_wb_xi = np.dot(w,x) + b # ciclo for, con i = 1 : m (i che varia da 1 a m) RICORDA: m è la dimensione degli elementi di x!!\n",
        " #f_wb = w*x[i] + b # x(i) ,, f_wb è la funzione di una generica retta\n",
        " cost = cost / (2*m) # incrementa il valore di cost con la somma del valore di cost della precedente iterazione e di ciò che è tra parentesi, dove:\n",
        "\n",
        " reg_cost = 0\n",
        " for J in range(n):\n",
        " red_cost += (w[j]**2)\n",
        " reg_cost = (lamda_/(2*m)) * reg_cost #f_wb è la retta presa in considerazione e y[i] è la distanza (altezza) del punto con la retta.\n",
        "\n",
        " #cost è stato incrementato, seguirà una nuova iterazione.\n",
        " total_cost = cost + reg_cost # concluso il ciclo for, total_cost sarà la cost_function completa\n",
        " return total_cost # return chiude la funzione compute_cost e mi conserva la variabile locale total_cost per il resto del codice. Rendendola globale\n",
        "\n",
        "np.random.seed(1)\n",
        "x_tmp = np.random.rand(5,6)\n",
        "y_tmp = np.array([0,1,0,1,0])\n",
        "w_tmp = np.random.rand(x_tmp.shape[1]).reshape(-1,)-0.5\n",
        "b_tmp = 0.5\n",
        "lamda_tmp = 0.7\n",
        "cost_tmp = compute_cost_linear_reg(x_tmp, y_tmp, w_tmp, b_tmp, lamda_tmp)\n",
        "\n",
        "print(\"Regularization cost:\", cost_tmp)\n",
        "\n",
        "\n",
        "#x_train = np.array([1.0, 2.0, 5.0, 4.0])\n",
        "#y_train = np.array([1.0, 2.0, 5.0, 4.0])\n",
        "\n",
        "#print(compute_cost(x_train, y_train, w = 0, b = 0))\n",
        "#print(compute_cost(x_train, y_train, w = 1/2, b = 0))\n",
        "#print(compute_cost(x_train, y_train, w = 1, b = 0))\n",
        "#print(compute_cost(x_train, y_train, w = 3/2, b = 0))\n",
        "\n",
        "#plt.plot(x_train, y_train)\n",
        "#plt.show()"
      ]
    }
  ]
}